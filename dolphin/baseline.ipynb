{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0b69bf",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80be862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "from scipy import stats #Analysis \n",
    "from scipy.stats import norm \n",
    "\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54881d81",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Windows\\\\Fonts\\\\NanumGothicLight.ttf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10548/1153941168.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#font_path = 'C:\\\\Users\\\\mtang\\\\AppData\\\\Local\\\\Microsoft\\\\Windows\\\\Fonts\\\\NanumSquare.ttf'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfont_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\\\WINDOWS\\\\Fonts\\\\NanumGothicLight.ttf'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfont_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFontProperties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfont_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mrc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'font'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36mget_name\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfont\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfont\u001b[0m \u001b[0mproperties\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \"\"\"\n\u001b[1;32m--> 724\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfindfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfamily_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36mget_font\u001b[1;34m(filename, hinting_factor)\u001b[0m\n\u001b[0;32m   1422\u001b[0m         \u001b[0mhinting_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text.hinting_factor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m     \u001b[1;31m# also key on the thread ID to prevent segfaults with multi-threading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m     return _get_font(filename, hinting_factor,\n\u001b[0m\u001b[0;32m   1425\u001b[0m                      \u001b[0m_kerning_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text.kerning_factor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m                      thread_id=threading.get_ident())\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\font_manager.py\u001b[0m in \u001b[0;36m_get_font\u001b[1;34m(filename, hinting_factor, _kerning_factor, thread_id)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1404\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_font\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhinting_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_kerning_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1405\u001b[1;33m     return ft2font.FT2Font(\n\u001b[0m\u001b[0;32m   1406\u001b[0m         filename, hinting_factor, _kerning_factor=_kerning_factor)\n\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Windows\\\\Fonts\\\\NanumGothicLight.ttf'"
     ]
    }
   ],
   "source": [
    "# 한글 폰트가 깨지면 실행하세요! \n",
    "# 한글 폰트가 따로 깔려있지 않은 컴퓨터에서는 해당 cell을 넘겨주세요!!! \n",
    "import matplotlib.font_manager as fm\n",
    "fontlist = fm.findSystemFonts(fontpaths = None, fontext='ttf')\n",
    "# 아래 주석을 지워서 폰트 리스트를 확인하고 한글 폰트를 font_path에 추가합니다\n",
    "fontlist[:]\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "#font_path = 'C:\\\\Users\\\\mtang\\\\AppData\\\\Local\\\\Microsoft\\\\Windows\\\\Fonts\\\\NanumSquare.ttf'\n",
    "font_path = 'C:\\\\WINDOWS\\\\Fonts\\\\NanumGothicLight.ttf'\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507af345",
   "metadata": {},
   "source": [
    "# 1. Data Load  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23305c3e",
   "metadata": {},
   "source": [
    "**치매 예방을 위한 라이프로그 치매 분류**\n",
    "\n",
    "**9,327 rows × 66 columns**\n",
    "\n",
    "For more details https://aihub.or.kr/problem_contest/nipa-learning-platform/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Dataset/\"\n",
    "\n",
    "# original data : data \n",
    "data =  pd.read_csv(path + \"dementia_data.csv\", parse_dates=['summary_date']) # 애초에 datatime 유형의 데이터를 읽어 올 때부터 형변환하기\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c72751",
   "metadata": {},
   "source": [
    "# 2. EDA  \n",
    "\n",
    "**9,327 rows × 66 columns**\n",
    "\n",
    "148명에 대한 데일리 라이프로그 데이터 \n",
    "크게 걸음거리, 수면, 컨버팅 데이터로 나눌 수 있겠습니다. \n",
    "\n",
    "**basic (3 cols)**\n",
    "- timezone 시간 장소 정보 \n",
    "    - drop \n",
    "    - 완벽한 null variable \n",
    "- EMAIL\n",
    "    - drop\n",
    "    - 식별자 feature \n",
    "- summary_date\n",
    "\n",
    "**activity (26 cols)**\n",
    "- activity_class_5min, activity_met_1min, 하루간 5분당 활동 로그,하루간 1분당 MET 로그\n",
    "    - drop \n",
    "    - BLOB type -> js로 읽을 수 있다고는 함 \n",
    "\n",
    "**sleep (31 cols)**\n",
    "- sleep_is_longest, 본 수면 여부 \n",
    "    - 전부 다 1 \n",
    "- sleep_temperature_trend_deviation, 피부 온도 경향 편차 \n",
    "    - 전부 다 99.99\n",
    "- sleep_total, 수면 시간 \n",
    "    - 전부 다 \\r\n",
    "- sleep_temperature_deviation \n",
    "    - drop \n",
    "    - sleep_temperature_delta 랑 같은 변수 \n",
    "    - sleep_temperature_deviation 을 drop 하고 delta를 남길 것 \n",
    "- sleep_hr_5min, sleep_hypnogram_5min, sleep_rmssd_5min\n",
    "    - 5분 당 심박동로그, 수면 상태 로그, 5분당 심박동변동 로그\n",
    "    - drop \n",
    "    - BLOB type \n",
    "\n",
    "**converting**\n",
    "- CONVERT(activity_class_5min USING utf8)    \n",
    "- CONVERT(activity_met_1min USING utf8)      \n",
    "- CONVERT(sleep_hr_5min USING utf8)          \n",
    "- CONVERT(sleep_hypnogram_5min USING utf8)  \n",
    "- CONVERT(sleep_rmssd_5min USING utf8) \n",
    "\n",
    "**y variable**\n",
    "- DIAG_NM \n",
    "    - 정상(CN), 경도인지 장애(MCI), 치매(Dem)\n",
    "    \n",
    "So we may use 56 columns for training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e37d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4808801",
   "metadata": {},
   "source": [
    "# 3. Preprocessing \n",
    "\n",
    "**9,327 rows × 66 columns**\n",
    "\n",
    "**9,327 rows × 51 columns**\n",
    "\n",
    "\n",
    "**feature drop**\n",
    "- timezone\n",
    "- EMAIL\n",
    "- sleep_temperature_trend_deviation, sleep_is_longest, sleep_total\n",
    "    - 모든 값이 1, '\\r', 99.99 이므로 제거 \n",
    "- activity_class_5min, activity_met_1min\n",
    "    - convert data\n",
    "- sleep_hr_5min, sleep_hypnogram_5min, sleep_rmssd_5min\n",
    "    - convert data\n",
    "\n",
    "\n",
    "- CONVERT(activity_class_5min USING utf8)    \n",
    "- CONVERT(activity_met_1min USING utf8)      \n",
    "- CONVERT(sleep_hr_5min USING utf8)          \n",
    "- CONVERT(sleep_hypnogram_5min USING utf8)  \n",
    "- CONVERT(sleep_rmssd_5min USING utf8) \n",
    "\n",
    "**y variable**\n",
    "- DIAG_NM \n",
    "    - 정상(CN), 경도인지 장애(MCI), 치매(Dem)\n",
    "    \n",
    "So we may use 56 columns for training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fd692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column의 수가 많기 때문에 효율적으로 관리하기 위해서 \n",
    "# column의 이름들을 묶어서 진행합시다\n",
    "drop_cols = ['timezone', 'EMAIL',\n",
    "             'activity_class_5min', 'activity_met_1min',\n",
    "             'sleep_hr_5min', 'sleep_hypnogram_5min', 'sleep_rmssd_5min',\n",
    "             'sleep_is_longest', 'sleep_temperature_trend_deviation', 'sleep_total', 'sleep_temperature_deviation']\n",
    "convert_cols = data.iloc[:, 60:65].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8646db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data -> processed_data \n",
    "# Drop Features \n",
    "processed_data = data.drop(drop_cols, axis=1).copy()\n",
    "processed_data = processed_data.drop(convert_cols, axis=1).copy()\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54b43c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10548/2114375619.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocessed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'summary_date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'processed_data' is not defined"
     ]
    }
   ],
   "source": [
    "processed_data = processed_data.drop('summary_date', axis=1).copy()\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520471a",
   "metadata": {},
   "source": [
    "# 4. Data Split \n",
    "\n",
    "모든 전처리와 y variable labeling이 완료되었다. train / valid / test data로 분할하고 용도에 맞게 model을 돌리도록 하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "90ecc027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\n",
    "\n",
    "# processed_data -> input_data \n",
    "input_data = processed_data.copy()\n",
    "\n",
    "# y 변수와 X 변수 분할 관리 \n",
    "input_data_y = input_data['DIAG_NM'].copy()\n",
    "input_data_X = input_data.drop(['DIAG_NM'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9c7b1e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original gain_label \n",
      " ['CN' 'Dem' 'MCI']\n",
      "gain_lable label \n",
      " {0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "# LabelEncoder\n",
    "# y data를 LabelEncdoer로 한 번 더 labeling 합니다 -> 100만원, 10000만원... = 0, 1, ... \n",
    "# 추후에 DL에서 output을 맞춰주기 위함입니다, 최종 마지막에서 원래 label값(100만원, 1000만원...)으로 되돌립니다\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "input_data_y = le.fit_transform(list(input_data_y))\n",
    "print(\"original gain_label \\n\", le.classes_)\n",
    "print(\"gain_lable label \\n\", set(input_data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3ca2315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/ test data 로 split \n",
    "tr_val_X, test_X, tr_val_y, test_y = train_test_split(\n",
    "    input_data_X, \n",
    "    input_data_y, \n",
    "    test_size = 0.2, \n",
    "    random_state = 42,\n",
    "    shuffle=True,\n",
    "    stratify = input_data_y # Classification 중요 option\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e012e",
   "metadata": {},
   "source": [
    "# 5. Modeling - ML\n",
    "\n",
    "- Linear model\n",
    "    - Logistic Linear Regression \n",
    "- Tree model \n",
    "    - RandomForest \n",
    "- Gradient Boosting model \n",
    "    - XGB\n",
    "    - LGBM\n",
    "    - CatBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "004ba734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import plot_importance \n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# Learning task parameters\n",
    "# multi:softmax : softmax를 이용한 다중 클래스 분류 \n",
    "# multi:softptob : softmax를 이용한 다중 클래스에 대한 예상 확률 반환 \n",
    "# mlogloss : multiclass logloss \n",
    "\n",
    "model_rf = RandomForestClassifier()\n",
    "\n",
    "model_xgb = XGBClassifier(\n",
    "    eval_metric='mlogloss', use_label_encoder=False )\n",
    "model_lgbm = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5a89cf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 : 0.491,  학습 데이터 크기 : 5968,  검증 데이터 크기 : 1493\n",
      "#1 검증 세트 인덱스 : [   0    1    2 ... 1523 1524 1525]\n",
      "\n",
      "#2 교차 검증 정확도 : 0.6408,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#2 검증 세트 인덱스 : [1418 1426 1435 ... 3169 3174 3179]\n",
      "\n",
      "#3 교차 검증 정확도 : 0.5657,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#3 검증 세트 인덱스 : [2970 2971 2972 ... 4530 4532 4561]\n",
      "\n",
      "#4 교차 검증 정확도 : 0.5597,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#4 검증 세트 인덱스 : [4448 4449 4450 ... 5998 5999 6000]\n",
      "\n",
      "#5 교차 검증 정확도 : 0.5268,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#5 검증 세트 인덱스 : [5918 5921 5926 ... 7458 7459 7460]\n",
      "\n",
      "## 평균 검증 정확도: 0.5568000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "n_iter =0\n",
    "\n",
    "for train_index, test_index in kfold.split(tr_val_X, tr_val_y):  # feautres 데이터를 위에서 지정한 kfold 숫자로 분할\n",
    "    x_train, x_test = input_data_X.iloc[train_index], input_data_X.iloc[test_index]\n",
    "    y_train, y_test = input_data_y[train_index], input_data_y[test_index]\n",
    "    \n",
    "    model_rf.fit(x_train, y_train)\n",
    "    pred = model_rf.predict(x_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4) # 소수점 4자리 반올림\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "    \n",
    "    print('\\n#{0} 교차 검증 정확도 : {1},  학습 데이터 크기 : {2},  검증 데이터 크기 : {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5c6d3cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 : 0.4796,  학습 데이터 크기 : 5968,  검증 데이터 크기 : 1493\n",
      "#1 검증 세트 인덱스 : [   0    1    2 ... 1523 1524 1525]\n",
      "\n",
      "#2 교차 검증 정확도 : 0.6193,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#2 검증 세트 인덱스 : [1418 1426 1435 ... 3169 3174 3179]\n",
      "\n",
      "#3 교차 검증 정확도 : 0.5181,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#3 검증 세트 인덱스 : [2970 2971 2972 ... 4530 4532 4561]\n",
      "\n",
      "#4 교차 검증 정확도 : 0.5536,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#4 검증 세트 인덱스 : [4448 4449 4450 ... 5998 5999 6000]\n",
      "\n",
      "#5 교차 검증 정확도 : 0.5228,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#5 검증 세트 인덱스 : [5918 5921 5926 ... 7458 7459 7460]\n",
      "\n",
      "## 평균 검증 정확도: 0.53868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "n_iter =0\n",
    "\n",
    "for train_index, test_index in kfold.split(tr_val_X, tr_val_y):  # feautres 데이터를 위에서 지정한 kfold 숫자로 분할\n",
    "    x_train, x_test = input_data_X.iloc[train_index], input_data_X.iloc[test_index]\n",
    "    y_train, y_test = input_data_y[train_index], input_data_y[test_index]\n",
    "    \n",
    "    model_xgb.fit(x_train, y_train)\n",
    "    pred = model_xgb.predict(x_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4) # 소수점 4자리 반올림\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "    \n",
    "    print('\\n#{0} 교차 검증 정확도 : {1},  학습 데이터 크기 : {2},  검증 데이터 크기 : {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8c12f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 : 0.4776,  학습 데이터 크기 : 5968,  검증 데이터 크기 : 1493\n",
      "#1 검증 세트 인덱스 : [   0    1    2 ... 1523 1524 1525]\n",
      "\n",
      "#2 교차 검증 정확도 : 0.6448,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#2 검증 세트 인덱스 : [1418 1426 1435 ... 3169 3174 3179]\n",
      "\n",
      "#3 교차 검증 정확도 : 0.5349,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#3 검증 세트 인덱스 : [2970 2971 2972 ... 4530 4532 4561]\n",
      "\n",
      "#4 교차 검증 정확도 : 0.5436,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#4 검증 세트 인덱스 : [4448 4449 4450 ... 5998 5999 6000]\n",
      "\n",
      "#5 교차 검증 정확도 : 0.5295,  학습 데이터 크기 : 5969,  검증 데이터 크기 : 1492\n",
      "#5 검증 세트 인덱스 : [5918 5921 5926 ... 7458 7459 7460]\n",
      "\n",
      "## 평균 검증 정확도: 0.5460800000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "n_iter =0\n",
    "\n",
    "for train_index, test_index in kfold.split(tr_val_X, tr_val_y):  # feautres 데이터를 위에서 지정한 kfold 숫자로 분할\n",
    "    x_train, x_test = input_data_X.iloc[train_index], input_data_X.iloc[test_index]\n",
    "    y_train, y_test = input_data_y[train_index], input_data_y[test_index]\n",
    "    \n",
    "    model_lgbm.fit(x_train, y_train)\n",
    "    pred = model_lgbm.predict(x_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4) # 소수점 4자리 반올림\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "    \n",
    "    print('\\n#{0} 교차 검증 정확도 : {1},  학습 데이터 크기 : {2},  검증 데이터 크기 : {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스 : {1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "21971df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = model_rf.predict(test_X)\n",
    "\n",
    "pred_xgb_prob = model_xgb.predict_proba(test_X)\n",
    "pred_xgb = np.argmax(pred_xgb_prob, axis=1)\n",
    "\n",
    "pred_lgbm_prob = model_lgbm.predict_proba(test_X)\n",
    "pred_lgbm = np.argmax(pred_lgbm_prob, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201440a",
   "metadata": {},
   "source": [
    "# 6. Evaluation\n",
    "\n",
    "- precision(정밀도) : True -> True \n",
    "- Recall(재현율) : True인 것을 맞춘 비율 \n",
    "- F1 score : precision 과 recall의 조화평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6c240a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pred(test_y, pred) :\n",
    "    true_y = test_y.to_numpy()\n",
    "    true_y = np.ravel(true_y)\n",
    "    \n",
    "    df_result = pd.DataFrame(list(zip(true_y, pred)), columns=['true_y', 'prediction'])\n",
    "    return df_result\n",
    "    \n",
    "def show_prediction_error(test_y, pred) :\n",
    "    true_y = test_y.to_numpy()\n",
    "    true_y = np.ravel(true_y)\n",
    "    error = pred - true_y\n",
    "    plt.hist(error, bins=25)\n",
    "    plt.xlabel(\"Prediction Error\")\n",
    "    _ = plt.ylabel(\"Count\")\n",
    "    \n",
    "def feature_importance(model_xgb) : \n",
    "    %matplotlib inline\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    font_path = \"C:/Windows/Fonts/NGULIM.TTF\"\n",
    "    font = fm.FontProperties(fname=font_path).get_name()\n",
    "    rc('font', family=font)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,12))\n",
    "    plot_importance(model_xgb, ax=ax)\n",
    "    \n",
    "def graph(pred, test_label) :\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.plot(test_label, label = 'actual')\n",
    "    plt.plot(pred, label = 'prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4f110bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      1194\n",
      "           1       0.90      0.84      0.87       129\n",
      "           2       0.92      0.70      0.79       543\n",
      "\n",
      "    accuracy                           0.88      1866\n",
      "   macro avg       0.90      0.83      0.86      1866\n",
      "weighted avg       0.88      0.88      0.87      1866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4ddfa4b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      1194\n",
      "           1       0.87      0.85      0.86       129\n",
      "           2       0.86      0.73      0.79       543\n",
      "\n",
      "    accuracy                           0.87      1866\n",
      "   macro avg       0.87      0.84      0.85      1866\n",
      "weighted avg       0.87      0.87      0.87      1866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "78083953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90      1194\n",
      "           1       0.89      0.87      0.88       129\n",
      "           2       0.86      0.73      0.79       543\n",
      "\n",
      "    accuracy                           0.87      1866\n",
      "   macro avg       0.87      0.84      0.86      1866\n",
      "weighted avg       0.87      0.87      0.87      1866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2891aae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
