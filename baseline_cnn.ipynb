{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0b69bf",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80be862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import random \n",
    "\n",
    "from scipy import stats #Analysis \n",
    "from scipy.stats import norm \n",
    "\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507af345",
   "metadata": {},
   "source": [
    "# 1. Data Load  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23305c3e",
   "metadata": {},
   "source": [
    "**치매 예방을 위한 라이프로그 치매 분류**\n",
    "\n",
    "**9,327 rows × 2 columns x 5 picture**\n",
    "\n",
    "For more details https://aihub.or.kr/problem_contest/nipa-learning-platform/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ff38bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CN_0.png</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN_1.png</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN_10.png</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN_1000.png</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CN_1001.png</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9322</th>\n",
       "      <td>MCI_95.png</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323</th>\n",
       "      <td>MCI_96.png</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>MCI_97.png</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9325</th>\n",
       "      <td>MCI_98.png</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>MCI_99.png</td>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9327 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename category\n",
       "0        CN_0.png       CN\n",
       "1        CN_1.png       CN\n",
       "2       CN_10.png       CN\n",
       "3     CN_1000.png       CN\n",
       "4     CN_1001.png       CN\n",
       "...           ...      ...\n",
       "9322   MCI_95.png      MCI\n",
       "9323   MCI_96.png      MCI\n",
       "9324   MCI_97.png      MCI\n",
       "9325   MCI_98.png      MCI\n",
       "9326   MCI_99.png      MCI\n",
       "\n",
       "[9327 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original data : data \n",
    "path = \"./Dataset/pic_dataset\"\n",
    "\n",
    "FAST_RUN = False\n",
    "IMAGE_WIDTH=128\n",
    "IMAGE_HEIGHT=128\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=1\n",
    "\n",
    "filenames = os.listdir(path)\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('_')[0]\n",
    "    categories.append(category)\n",
    "#    if category == 'CN':\n",
    "#        categories.append(0)\n",
    "#    elif  category == 'MCI':\n",
    "#        categories.append(1)\n",
    "#    else:\n",
    "#        categories.append(2)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c72751",
   "metadata": {},
   "source": [
    "# 2. EDA  \n",
    "\n",
    "**9,327 rows × 66 columns**\n",
    "\n",
    "148명에 대한 데일리 라이프로그 데이터  \n",
    "크게 **1. 기본 정보 2. 걸음거리 3.수면 4.컨버팅 데이터**로 나눌 수 있겠습니다. \n",
    "\n",
    "**4. converting**\n",
    "- CONVERT(activity_class_5min USING utf8)    \n",
    "- CONVERT(activity_met_1min USING utf8)      \n",
    "- CONVERT(sleep_hr_5min USING utf8)          \n",
    "- CONVERT(sleep_hypnogram_5min USING utf8)  \n",
    "- CONVERT(sleep_rmssd_5min USING utf8) \n",
    "\n",
    "**y variable**\n",
    "- DIAG_NM \n",
    "    - 정상(CN), 경도인지 장애(MCI), 치매(Dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9e37d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9327 entries, 0 to 9326\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   filename  9327 non-null   object\n",
      " 1   category  9327 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 145.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4808801",
   "metadata": {},
   "source": [
    "# 3. Preprocessing \n",
    "\n",
    "**9,327 rows × 2 columns × 5 pictures**\n",
    "\n",
    "|**===================Default 하게 진행======================**\n",
    "\n",
    "CNN 모델에서는 converting feature를 png로 변환한 데이터를 사용할 예정 (이와 관련하여 create_pic_dataset.ipynb 참고할 것!)\n",
    "\n",
    "**feature processing**\n",
    "- astype : float \n",
    "- sig1_data, sig2_data, sig3_data, sig4_data, sig5_data \n",
    "    - CONVERT(activity_class_5min USING utf8)    \n",
    "    - CONVERT(activity_met_1min USING utf8)      \n",
    "    - CONVERT(sleep_hr_5min USING utf8)          \n",
    "    - CONVERT(sleep_hypnogram_5min USING utf8)  \n",
    "    - CONVERT(sleep_rmssd_5min USING utf8) \n",
    "\n",
    "**=========================Y Varible=========================**\n",
    "\n",
    "- DIAG_NM \n",
    "    - 정상(CN), 경도인지 장애(MCI), 치매(Dem)\n",
    "    - Lable Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724c5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data를 따로 관리합니다 \n",
    "# original data -> data \n",
    "# preprocessing data -> processed_data\n",
    "processed_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af7612b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fb29a5b880>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sample = random.choice(filenames)\n",
    "image = tf.keras.preprocessing.image.load_img (path+\"/\"+sample)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88c03afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b09af",
   "metadata": {},
   "source": [
    "Autoencoder -> input 이미지 하면 -> encoder -> 벡터로 표현\n",
    "\n",
    "지금 Autoencoder가 이미지를 받는지 벡터를 받는지 모르겠음.\n",
    "벡터인 것 같아서 이미지를 벡터로 변환하는게 필요함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334c0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "913b86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./Dataset/pic_datset/CN_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4faf3ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520471a",
   "metadata": {},
   "source": [
    "# 4. Data Split \n",
    "\n",
    "train / valid / test data로 분할\n",
    "\n",
    "- **ImageDataGenerator** \n",
    "    - CNN이 image data를 학습하기 위해서는 특별히 전처리를 진행해주어야 함 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c89646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.utils import load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data를 따로 관리\n",
    "# preprocessing data -> processed_data\n",
    "# train_data / valid_data / test_data 분할 \n",
    "# 이 중 test_data -> test_X / test_y 로 한 번 더 분할\n",
    "\n",
    "tr_val_data, test_data = train_test_split(processed_data, test_size=0.20, random_state=42)\n",
    "train_data, valid_data = train_test_split(tr_val_data, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "753254c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5968 validated image filenames belonging to 3 classes.\n",
      "Found 1493 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# parameter\n",
    "batch_size=15\n",
    "\n",
    "# image learning을 위한 preprocessing : ImageDataGenerator \n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_data, \n",
    "    path, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    valid_data, \n",
    "    path, \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac3d597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# parameter\n",
    "batch_size=15\n",
    "\n",
    "# image learning을 위한 preprocessing : ImageDataGenerator \n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory('Dataset/pic_dataset',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary'\n",
    ")\n",
    "\n",
    "# validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# validation_generator = validation_datagen.flow_from_dataframe(\n",
    "#     valid_data, \n",
    "#     path, \n",
    "#     x_col='filename',\n",
    "#     y_col='filename',\n",
    "#     target_size=IMAGE_SIZE,\n",
    "#     color_mode='grayscale',\n",
    "#     class_mode='categorical',\n",
    "#     batch_size=batch_size\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abb5e4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.ImageDataGenerator at 0x1f48cd57340>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e012e",
   "metadata": {},
   "source": [
    "# 5. Modeling - DL \n",
    "\n",
    "- **CNN**\n",
    "    - https://dataplay.tistory.com/37?category=845492\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8802e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c915f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "earlystop = EarlyStopping(patience=30)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction]\n",
    "\n",
    "total_train = train_data.shape[0]\n",
    "total_validate = valid_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95fa5d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 48)        13872     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 48)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 48)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        27712     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 96)        55392     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 96)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8, 8, 96)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6144)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1573120   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,671,187\n",
      "Trainable params: 1,671,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, 3, activation='relu', padding=\"same\", input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(48, 3, activation='relu', padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, 3, activation='relu', padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(96, 3, activation='relu', padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a33747",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.8954 - accuracy: 0.6390WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 58s 145ms/step - loss: 0.8954 - accuracy: 0.6390 - val_loss: 0.8325 - val_accuracy: 0.6337 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.8360 - accuracy: 0.6445WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 58s 146ms/step - loss: 0.8360 - accuracy: 0.6445 - val_loss: 0.8255 - val_accuracy: 0.6323 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.8259 - accuracy: 0.6447WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 61s 155ms/step - loss: 0.8259 - accuracy: 0.6447 - val_loss: 0.8027 - val_accuracy: 0.6330 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.8084 - accuracy: 0.6442WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 147ms/step - loss: 0.8084 - accuracy: 0.6442 - val_loss: 0.7838 - val_accuracy: 0.6350 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.8012 - accuracy: 0.6454WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 148ms/step - loss: 0.8012 - accuracy: 0.6454 - val_loss: 0.8011 - val_accuracy: 0.6337 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7888 - accuracy: 0.6456WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 149ms/step - loss: 0.7888 - accuracy: 0.6456 - val_loss: 0.7696 - val_accuracy: 0.6350 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7866 - accuracy: 0.6493WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 57s 144ms/step - loss: 0.7866 - accuracy: 0.6493 - val_loss: 0.7659 - val_accuracy: 0.6384 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7846 - accuracy: 0.6501WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 149ms/step - loss: 0.7846 - accuracy: 0.6501 - val_loss: 0.7790 - val_accuracy: 0.6404 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7761 - accuracy: 0.6516WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 60s 150ms/step - loss: 0.7761 - accuracy: 0.6516 - val_loss: 0.7577 - val_accuracy: 0.6458 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7695 - accuracy: 0.6501WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 60s 150ms/step - loss: 0.7695 - accuracy: 0.6501 - val_loss: 0.7594 - val_accuracy: 0.6478 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7677 - accuracy: 0.6533WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 57s 145ms/step - loss: 0.7677 - accuracy: 0.6533 - val_loss: 0.7565 - val_accuracy: 0.6478 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7818 - accuracy: 0.6541WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 61s 153ms/step - loss: 0.7818 - accuracy: 0.6541 - val_loss: 0.7560 - val_accuracy: 0.6512 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7694 - accuracy: 0.6541WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 148ms/step - loss: 0.7694 - accuracy: 0.6541 - val_loss: 0.7691 - val_accuracy: 0.6431 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7720 - accuracy: 0.6540WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 58s 145ms/step - loss: 0.7720 - accuracy: 0.6540 - val_loss: 0.7869 - val_accuracy: 0.6404 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7685 - accuracy: 0.6536WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 60s 151ms/step - loss: 0.7685 - accuracy: 0.6536 - val_loss: 0.7568 - val_accuracy: 0.6465 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7674 - accuracy: 0.6568WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 60s 151ms/step - loss: 0.7674 - accuracy: 0.6568 - val_loss: 0.7615 - val_accuracy: 0.6492 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7648 - accuracy: 0.6526WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 57s 143ms/step - loss: 0.7648 - accuracy: 0.6526 - val_loss: 0.7505 - val_accuracy: 0.6451 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7677 - accuracy: 0.6546WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 60s 150ms/step - loss: 0.7677 - accuracy: 0.6546 - val_loss: 0.7628 - val_accuracy: 0.6519 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7751 - accuracy: 0.6575WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 57s 144ms/step - loss: 0.7751 - accuracy: 0.6575 - val_loss: 0.7826 - val_accuracy: 0.6478 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7572 - accuracy: 0.6600WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 149ms/step - loss: 0.7572 - accuracy: 0.6600 - val_loss: 0.7792 - val_accuracy: 0.6431 - lr: 0.0010\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 0.7615 - accuracy: 0.6571WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 57s 144ms/step - loss: 0.7615 - accuracy: 0.6571 - val_loss: 0.7580 - val_accuracy: 0.6539 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7652 - accuracy: 0.6588WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 57s 144ms/step - loss: 0.7652 - accuracy: 0.6588 - val_loss: 0.7572 - val_accuracy: 0.6431 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7626 - accuracy: 0.6558WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 62s 156ms/step - loss: 0.7626 - accuracy: 0.6558 - val_loss: 0.7480 - val_accuracy: 0.6505 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7563 - accuracy: 0.6612WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 148ms/step - loss: 0.7563 - accuracy: 0.6612 - val_loss: 0.7552 - val_accuracy: 0.6525 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7677 - accuracy: 0.6598WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 150ms/step - loss: 0.7677 - accuracy: 0.6598 - val_loss: 0.7491 - val_accuracy: 0.6471 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.6605WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 60s 152ms/step - loss: 0.7646 - accuracy: 0.6605 - val_loss: 0.7701 - val_accuracy: 0.6465 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7623 - accuracy: 0.6556WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 60s 150ms/step - loss: 0.7623 - accuracy: 0.6556 - val_loss: 0.7486 - val_accuracy: 0.6498 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7647 - accuracy: 0.6610WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 148ms/step - loss: 0.7647 - accuracy: 0.6610 - val_loss: 0.7626 - val_accuracy: 0.6444 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7681 - accuracy: 0.6597WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 60s 151ms/step - loss: 0.7681 - accuracy: 0.6597 - val_loss: 0.7686 - val_accuracy: 0.6438 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7606 - accuracy: 0.6593WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 149ms/step - loss: 0.7606 - accuracy: 0.6593 - val_loss: 0.7440 - val_accuracy: 0.6566 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7596 - accuracy: 0.6615WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 66s 166ms/step - loss: 0.7596 - accuracy: 0.6615 - val_loss: 0.7518 - val_accuracy: 0.6451 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7631 - accuracy: 0.6619WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 69s 173ms/step - loss: 0.7631 - accuracy: 0.6619 - val_loss: 0.7539 - val_accuracy: 0.6525 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7595 - accuracy: 0.6629WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 68s 171ms/step - loss: 0.7595 - accuracy: 0.6629 - val_loss: 0.7509 - val_accuracy: 0.6471 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7667 - accuracy: 0.6603WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 71s 179ms/step - loss: 0.7667 - accuracy: 0.6603 - val_loss: 0.7524 - val_accuracy: 0.6498 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7582 - accuracy: 0.6627WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 60s 152ms/step - loss: 0.7582 - accuracy: 0.6627 - val_loss: 0.7659 - val_accuracy: 0.6471 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7581 - accuracy: 0.6649WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 59s 150ms/step - loss: 0.7581 - accuracy: 0.6649 - val_loss: 0.7648 - val_accuracy: 0.6465 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7585 - accuracy: 0.6622WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 57s 144ms/step - loss: 0.7585 - accuracy: 0.6622 - val_loss: 0.7515 - val_accuracy: 0.6498 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7625 - accuracy: 0.6640WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 57s 144ms/step - loss: 0.7625 - accuracy: 0.6640 - val_loss: 0.7531 - val_accuracy: 0.6444 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7696 - accuracy: 0.6634WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 57s 144ms/step - loss: 0.7696 - accuracy: 0.6634 - val_loss: 0.7564 - val_accuracy: 0.6512 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7714 - accuracy: 0.6619WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 57s 144ms/step - loss: 0.7714 - accuracy: 0.6619 - val_loss: 0.7654 - val_accuracy: 0.6465 - lr: 0.0010\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - ETA: 0s - loss: 0.7678 - accuracy: 0.6654WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 58s 146ms/step - loss: 0.7678 - accuracy: 0.6654 - val_loss: 0.7550 - val_accuracy: 0.6478 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "397/397 [==============================] - ETA: 0s - loss: 0.7686 - accuracy: 0.6630WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "397/397 [==============================] - 58s 147ms/step - loss: 0.7686 - accuracy: 0.6630 - val_loss: 0.7836 - val_accuracy: 0.6458 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "252/397 [==================>...........] - ETA: 20s - loss: 0.7595 - accuracy: 0.6599"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7fbc4581965a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mFAST_RUN\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pythontemp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pythontemp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pythontemp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pythontemp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pythontemp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pythontemp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pythontemp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\pythontemp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pythontemp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=3 if FAST_RUN else 50\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='valid loss')\n",
    "plt.xticks(range(len(history.history['loss'])))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('precision')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc536f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cnn = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6869c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
